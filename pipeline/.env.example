# LLM Provider Configuration
# Options: openai, anthropic, groq
LLM_PROVIDER=groq

# API Keys (provide the key for your chosen provider)
GROQ_API_KEY=your-groq-api-key-here
# OPENAI_API_KEY=your-openai-api-key-here
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# LLM Model Configuration
# Groq: llama-3.3-70b-versatile, llama-3.1-70b-versatile, mixtral-8x7b-32768
# OpenAI: gpt-4, gpt-3.5-turbo
# Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
LLM_MODEL=llama-3.3-70b-versatile

# LLM Parameters
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2000

# Vector Search API
VECTOR_SEARCH_URL=http://localhost:5001

# RAG Orchestrator API
RAG_API_PORT=8000
RAG_API_HOST=0.0.0.0

# Storage Paths (relative to pipeline directory)
STORAGE_UPLOADS_PATH=storage/uploads
STORAGE_CHUNKS_PATH=storage/chunks
VECTOR_INDEX_PATH=embed-and-vec-search/vector_index

# Copy this file to .env and replace with your actual values
